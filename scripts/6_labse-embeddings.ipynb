{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:18:02.836978Z",
     "start_time": "2025-07-23T13:17:58.641114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "import os\n",
    "import os, json\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer"
   ],
   "id": "e5b17d2ab853cb62",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 15:18:01.297135: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-23 15:18:01.306734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753276681.318245 3603422 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753276681.321435 3603422 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753276681.330022 3603422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753276681.330037 3603422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753276681.330038 3603422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753276681.330039 3603422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-23 15:18:01.333407: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e9c52bd3f3f7df31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:18:09.137199Z",
     "start_time": "2025-07-23T13:18:06.045656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load LaBSE model and push to GPU\n",
    "model = SentenceTransformer(\"sentence-transformers/LaBSE\")\n",
    "device = \"cuda\"  # ensure GPU is used\n",
    "\n",
    "# Encode in batches\n",
    "batch_size = 256\n",
    "model_name = \"LaBSE\""
   ],
   "id": "bedfe026d3115b02",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T21:41:05.119927Z",
     "start_time": "2025-07-21T21:41:05.116095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.cuda.max_memory_allocated() / 1e9, \"GB\")"
   ],
   "id": "30ada8faadb05fd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.772739584 GB\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-23T13:18:17.993668Z",
     "start_time": "2025-07-23T13:18:17.972506Z"
    }
   },
   "source": "conn = duckdb.connect(\"/srv/data/grela_v0-2.duckdb\")",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:18:38.021371Z",
     "start_time": "2025-07-23T13:18:37.999355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Query to get table and column information\n",
    "query = \"\"\"\n",
    "    SELECT\n",
    "        table_name,\n",
    "        column_name,\n",
    "        data_type,\n",
    "        is_nullable,\n",
    "        column_default\n",
    "    FROM information_schema.columns\n",
    "    ORDER BY table_name, ordinal_position\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch the schema information as a DataFrame\n",
    "df = conn.execute(query).fetchdf()\n",
    "\n",
    "# Group the schema details by table\n",
    "tables = df.groupby(\"table_name\")\n",
    "\n",
    "# Markdown generation\n",
    "markdown = \"# Database Schema Documentation\\n\\n\"\n",
    "for table_name, group in tables:\n",
    "    markdown += f\"## Table: `{table_name}`\\n\\n\"\n",
    "    markdown += \"| Column Name     | Data Type    | Is Nullable | Default Value |\\n\"\n",
    "    markdown += \"|-----------------|-------------|-------------|---------------|\\n\"\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        markdown += (\n",
    "            f\"| {row['column_name']} | {row['data_type']} | \"\n",
    "            f\"{row['is_nullable']} | {row['column_default'] or 'N/A'} |\\n\"\n",
    "        )\n",
    "\n",
    "    markdown += \"\\n\"  # Add a space between tables"
   ],
   "id": "2922d7bf44b9dc85",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:18:38.644854Z",
     "start_time": "2025-07-23T13:18:38.641630Z"
    }
   },
   "cell_type": "code",
   "source": "print(markdown)",
   "id": "2d36391973d6e1d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Database Schema Documentation\n",
      "\n",
      "## Table: `sentence_embeddings`\n",
      "\n",
      "| Column Name     | Data Type    | Is Nullable | Default Value |\n",
      "|-----------------|-------------|-------------|---------------|\n",
      "| sentence_id | VARCHAR | NO | N/A |\n",
      "| grela_id | VARCHAR | YES | N/A |\n",
      "| model | VARCHAR | YES | N/A |\n",
      "| embedding | JSON | YES | N/A |\n",
      "\n",
      "## Table: `sentences`\n",
      "\n",
      "| Column Name     | Data Type    | Is Nullable | Default Value |\n",
      "|-----------------|-------------|-------------|---------------|\n",
      "| sentence_id | VARCHAR | YES | N/A |\n",
      "| grela_id | VARCHAR | YES | N/A |\n",
      "| position | INTEGER | YES | N/A |\n",
      "| text | VARCHAR | YES | N/A |\n",
      "| subwork_id | VARCHAR | YES | N/A |\n",
      "\n",
      "## Table: `tokens`\n",
      "\n",
      "| Column Name     | Data Type    | Is Nullable | Default Value |\n",
      "|-----------------|-------------|-------------|---------------|\n",
      "| sentence_id | VARCHAR | YES | N/A |\n",
      "| grela_id | VARCHAR | YES | N/A |\n",
      "| token_text | VARCHAR | YES | N/A |\n",
      "| lemma | VARCHAR | YES | N/A |\n",
      "| pos | VARCHAR | YES | N/A |\n",
      "| char_start | INTEGER | YES | N/A |\n",
      "| char_end | INTEGER | YES | N/A |\n",
      "| token_id | BIGINT | YES | N/A |\n",
      "\n",
      "## Table: `works`\n",
      "\n",
      "| Column Name     | Data Type    | Is Nullable | Default Value |\n",
      "|-----------------|-------------|-------------|---------------|\n",
      "| grela_source | VARCHAR | YES | N/A |\n",
      "| grela_id | VARCHAR | YES | N/A |\n",
      "| author | VARCHAR | YES | N/A |\n",
      "| title | VARCHAR | YES | N/A |\n",
      "| not_before | DOUBLE | YES | N/A |\n",
      "| not_after | DOUBLE | YES | N/A |\n",
      "| lagt_tlg_epithet | VARCHAR | YES | N/A |\n",
      "| lagt_genre | VARCHAR | YES | N/A |\n",
      "| lagt_provenience | VARCHAR | YES | N/A |\n",
      "| noscemus_place | VARCHAR | YES | N/A |\n",
      "| noscemus_genre | VARCHAR | YES | N/A |\n",
      "| noscemus_discipline | VARCHAR | YES | N/A |\n",
      "| title_short | VARCHAR | YES | N/A |\n",
      "| emlap_noscemus_id | DOUBLE | YES | N/A |\n",
      "| place_publication | VARCHAR | YES | N/A |\n",
      "| place_geonames | VARCHAR | YES | N/A |\n",
      "| author_viaf | DOUBLE | YES | N/A |\n",
      "| title_viaf | DOUBLE | YES | N/A |\n",
      "| date_random | DOUBLE | YES | N/A |\n",
      "| token_count | BIGINT | YES | 0 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T21:55:07.540687Z",
     "start_time": "2025-07-21T21:55:07.511530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create table for embeddings (if not exists)\n",
    "conn.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sentence_embeddings (\n",
    "    sentence_id TEXT PRIMARY KEY,\n",
    "    grela_id TEXT,\n",
    "    model TEXT,\n",
    "    embedding JSON\n",
    ")\n",
    "\"\"\")"
   ],
   "id": "8e036bedda7f7594",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7bf940189130>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T21:55:14.137207Z",
     "start_time": "2025-07-21T21:55:14.102388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load all Vulgate sentences\n",
    "query = \"\"\"\n",
    "SELECT sentence_id, grela_id, text\n",
    "FROM sentences\n",
    "WHERE grela_id LIKE 'vulgate_%'\n",
    "\"\"\"\n",
    "df = conn.execute(query).fetchdf()"
   ],
   "id": "e1fdcf602ad2eb04",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T21:55:25.315756Z",
     "start_time": "2025-07-21T21:55:25.311818Z"
    }
   },
   "cell_type": "code",
   "source": "len(df)",
   "id": "3812266ed6d01e4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35254"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T22:04:27.331293Z",
     "start_time": "2025-07-21T21:56:25.485757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df.iloc[i:i + batch_size]\n",
    "    print(f\"Encoding batch {i}–{i + len(batch)}\")\n",
    "\n",
    "    # Encode with GPU\n",
    "    embeddings = model.encode(batch[\"text\"].tolist(), convert_to_numpy=True, device=device)\n",
    "\n",
    "    # Insert into DuckDB\n",
    "    for j, row in batch.iterrows():\n",
    "        emb_vector = embeddings[j - i].tolist()\n",
    "        conn.execute(\"\"\"\n",
    "            INSERT OR REPLACE INTO sentence_embeddings (sentence_id, grela_id, model, embedding)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "        \"\"\", (row[\"sentence_id\"], row[\"grela_id\"], model_name, json.dumps(emb_vector)))"
   ],
   "id": "b38eb8a4b938de99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding batch 0–256\n",
      "Encoding batch 256–512\n",
      "Encoding batch 512–768\n",
      "Encoding batch 768–1024\n",
      "Encoding batch 1024–1280\n",
      "Encoding batch 1280–1536\n",
      "Encoding batch 1536–1792\n",
      "Encoding batch 1792–2048\n",
      "Encoding batch 2048–2304\n",
      "Encoding batch 2304–2560\n",
      "Encoding batch 2560–2816\n",
      "Encoding batch 2816–3072\n",
      "Encoding batch 3072–3328\n",
      "Encoding batch 3328–3584\n",
      "Encoding batch 3584–3840\n",
      "Encoding batch 3840–4096\n",
      "Encoding batch 4096–4352\n",
      "Encoding batch 4352–4608\n",
      "Encoding batch 4608–4864\n",
      "Encoding batch 4864–5120\n",
      "Encoding batch 5120–5376\n",
      "Encoding batch 5376–5632\n",
      "Encoding batch 5632–5888\n",
      "Encoding batch 5888–6144\n",
      "Encoding batch 6144–6400\n",
      "Encoding batch 6400–6656\n",
      "Encoding batch 6656–6912\n",
      "Encoding batch 6912–7168\n",
      "Encoding batch 7168–7424\n",
      "Encoding batch 7424–7680\n",
      "Encoding batch 7680–7936\n",
      "Encoding batch 7936–8192\n",
      "Encoding batch 8192–8448\n",
      "Encoding batch 8448–8704\n",
      "Encoding batch 8704–8960\n",
      "Encoding batch 8960–9216\n",
      "Encoding batch 9216–9472\n",
      "Encoding batch 9472–9728\n",
      "Encoding batch 9728–9984\n",
      "Encoding batch 9984–10240\n",
      "Encoding batch 10240–10496\n",
      "Encoding batch 10496–10752\n",
      "Encoding batch 10752–11008\n",
      "Encoding batch 11008–11264\n",
      "Encoding batch 11264–11520\n",
      "Encoding batch 11520–11776\n",
      "Encoding batch 11776–12032\n",
      "Encoding batch 12032–12288\n",
      "Encoding batch 12288–12544\n",
      "Encoding batch 12544–12800\n",
      "Encoding batch 12800–13056\n",
      "Encoding batch 13056–13312\n",
      "Encoding batch 13312–13568\n",
      "Encoding batch 13568–13824\n",
      "Encoding batch 13824–14080\n",
      "Encoding batch 14080–14336\n",
      "Encoding batch 14336–14592\n",
      "Encoding batch 14592–14848\n",
      "Encoding batch 14848–15104\n",
      "Encoding batch 15104–15360\n",
      "Encoding batch 15360–15616\n",
      "Encoding batch 15616–15872\n",
      "Encoding batch 15872–16128\n",
      "Encoding batch 16128–16384\n",
      "Encoding batch 16384–16640\n",
      "Encoding batch 16640–16896\n",
      "Encoding batch 16896–17152\n",
      "Encoding batch 17152–17408\n",
      "Encoding batch 17408–17664\n",
      "Encoding batch 17664–17920\n",
      "Encoding batch 17920–18176\n",
      "Encoding batch 18176–18432\n",
      "Encoding batch 18432–18688\n",
      "Encoding batch 18688–18944\n",
      "Encoding batch 18944–19200\n",
      "Encoding batch 19200–19456\n",
      "Encoding batch 19456–19712\n",
      "Encoding batch 19712–19968\n",
      "Encoding batch 19968–20224\n",
      "Encoding batch 20224–20480\n",
      "Encoding batch 20480–20736\n",
      "Encoding batch 20736–20992\n",
      "Encoding batch 20992–21248\n",
      "Encoding batch 21248–21504\n",
      "Encoding batch 21504–21760\n",
      "Encoding batch 21760–22016\n",
      "Encoding batch 22016–22272\n",
      "Encoding batch 22272–22528\n",
      "Encoding batch 22528–22784\n",
      "Encoding batch 22784–23040\n",
      "Encoding batch 23040–23296\n",
      "Encoding batch 23296–23552\n",
      "Encoding batch 23552–23808\n",
      "Encoding batch 23808–24064\n",
      "Encoding batch 24064–24320\n",
      "Encoding batch 24320–24576\n",
      "Encoding batch 24576–24832\n",
      "Encoding batch 24832–25088\n",
      "Encoding batch 25088–25344\n",
      "Encoding batch 25344–25600\n",
      "Encoding batch 25600–25856\n",
      "Encoding batch 25856–26112\n",
      "Encoding batch 26112–26368\n",
      "Encoding batch 26368–26624\n",
      "Encoding batch 26624–26880\n",
      "Encoding batch 26880–27136\n",
      "Encoding batch 27136–27392\n",
      "Encoding batch 27392–27648\n",
      "Encoding batch 27648–27904\n",
      "Encoding batch 27904–28160\n",
      "Encoding batch 28160–28416\n",
      "Encoding batch 28416–28672\n",
      "Encoding batch 28672–28928\n",
      "Encoding batch 28928–29184\n",
      "Encoding batch 29184–29440\n",
      "Encoding batch 29440–29696\n",
      "Encoding batch 29696–29952\n",
      "Encoding batch 29952–30208\n",
      "Encoding batch 30208–30464\n",
      "Encoding batch 30464–30720\n",
      "Encoding batch 30720–30976\n",
      "Encoding batch 30976–31232\n",
      "Encoding batch 31232–31488\n",
      "Encoding batch 31488–31744\n",
      "Encoding batch 31744–32000\n",
      "Encoding batch 32000–32256\n",
      "Encoding batch 32256–32512\n",
      "Encoding batch 32512–32768\n",
      "Encoding batch 32768–33024\n",
      "Encoding batch 33024–33280\n",
      "Encoding batch 33280–33536\n",
      "Encoding batch 33536–33792\n",
      "Encoding batch 33792–34048\n",
      "Encoding batch 34048–34304\n",
      "Encoding batch 34304–34560\n",
      "Encoding batch 34560–34816\n",
      "Encoding batch 34816–35072\n",
      "Encoding batch 35072–35254\n",
      "CPU times: user 4min 26s, sys: 2min 37s, total: 7min 3s\n",
      "Wall time: 8min 1s\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:22:41.641368Z",
     "start_time": "2025-07-23T13:20:51.748405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load all register sentences\n",
    "query = \"\"\"\n",
    "SELECT sentence_id, grela_id, text\n",
    "FROM sentences\n",
    "WHERE grela_id LIKE 'cc_10265'\n",
    "\"\"\"\n",
    "df = conn.execute(query).fetchdf()\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df.iloc[i:i + batch_size]\n",
    "    print(f\"Encoding batch {i}–{i + len(batch)}\")\n",
    "\n",
    "    # Encode with GPU\n",
    "    embeddings = model.encode(batch[\"text\"].tolist(), convert_to_numpy=True, device=device)\n",
    "\n",
    "    # Insert into DuckDB\n",
    "    for j, row in batch.iterrows():\n",
    "        emb_vector = embeddings[j - i].tolist()\n",
    "        conn.execute(\"\"\"\n",
    "            INSERT OR REPLACE INTO sentence_embeddings (sentence_id, grela_id, model, embedding)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "        \"\"\", (row[\"sentence_id\"], row[\"grela_id\"], model_name, json.dumps(emb_vector)))"
   ],
   "id": "78776f743835c23f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding batch 0–256\n",
      "Encoding batch 256–512\n",
      "Encoding batch 512–768\n",
      "Encoding batch 768–1024\n",
      "Encoding batch 1024–1280\n",
      "Encoding batch 1280–1536\n",
      "Encoding batch 1536–1792\n",
      "Encoding batch 1792–2048\n",
      "Encoding batch 2048–2304\n",
      "Encoding batch 2304–2560\n",
      "Encoding batch 2560–2816\n",
      "Encoding batch 2816–3072\n",
      "Encoding batch 3072–3328\n",
      "Encoding batch 3328–3584\n",
      "Encoding batch 3584–3840\n",
      "Encoding batch 3840–4096\n",
      "Encoding batch 4096–4352\n",
      "Encoding batch 4352–4608\n",
      "Encoding batch 4608–4864\n",
      "Encoding batch 4864–5120\n",
      "Encoding batch 5120–5376\n",
      "Encoding batch 5376–5399\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T22:11:32.830502Z",
     "start_time": "2025-07-21T22:11:32.330432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "        SELECT\n",
    "            s.grela_id,\n",
    "            s.sentence_id,\n",
    "            s.text\n",
    "        FROM sentences s\n",
    "        JOIN works w ON s.grela_id = w.grela_id\n",
    "        WHERE (w.not_before > 1000 AND w.not_before < 1100)\n",
    "           OR (w.not_after > 1000 AND w.not_after < 1100);\n",
    "\"\"\"\n",
    "df = conn.execute(query).fetchdf()"
   ],
   "id": "92793abce8642c64",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T22:11:34.777241Z",
     "start_time": "2025-07-21T22:11:34.774443Z"
    }
   },
   "cell_type": "code",
   "source": "len(df)",
   "id": "339ff5dc99aa8c13",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357091"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T03:48:30.868277Z",
     "start_time": "2025-07-21T22:37:46.799200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df.iloc[i:i + batch_size]\n",
    "    # Encode with GPU\n",
    "    embeddings = model.encode(batch[\"text\"].tolist(), convert_to_numpy=True, device=device)\n",
    "\n",
    "    # Insert into DuckDB\n",
    "    for j, row in batch.iterrows():\n",
    "        emb_vector = embeddings[j - i].tolist()\n",
    "        conn.execute(\"\"\"\n",
    "            INSERT OR REPLACE INTO sentence_embeddings (sentence_id, grela_id, model, embedding)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "        \"\"\", (row[\"sentence_id\"], row[\"grela_id\"], model_name, json.dumps(emb_vector)))"
   ],
   "id": "3a2e0efeb855945",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 11min 26s, sys: 1h 53min 47s, total: 5h 5min 14s\n",
      "Wall time: 5h 10min 44s\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:22:53.881253Z",
     "start_time": "2025-07-23T13:22:49.876113Z"
    }
   },
   "cell_type": "code",
   "source": "conn.close()",
   "id": "8a70a89a714452f6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "db6dffc5ec2912c6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
