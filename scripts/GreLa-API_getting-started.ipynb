{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:52:48.076309Z",
     "start_time": "2025-07-31T18:52:48.072831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import os\n",
    "import os, json\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)"
   ],
   "id": "10a1a40addaefa80",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:22:46.763167Z",
     "start_time": "2025-07-31T18:22:46.759915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the database is available on the following endpoint:\n",
    "api_url = \"https://ccs-lab.zcu.cz/grela-api/api/query\""
   ],
   "id": "d4432ae5315a43ab",
   "execution_count": 48,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The database is publicly available online from the following endpoint:\n",
    "\n",
    "```bash\n",
    "https://ccs-lab.zcu.cz/grela-api/api/query\n",
    "```\n",
    "\n",
    "Through the API, you can query it using the same queries as the local version.\n",
    "\n",
    "For instance, to retrieve the first 10 rows from  the `works` table, your SQL query would be:\n",
    "```\n",
    "SELECT * FROM works LIMIT 10;\n",
    "```\n",
    "\n",
    "To execute the query from the command line, you could use the `curl` command, e.g.:\n",
    "```bash\n",
    "curl -X POST https://ccs-lab.zcu.cz/grela-api/api/query \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"query\": \"SELECT * FROM works\", \"format\": \"json\"}'\n",
    "```"
   ],
   "id": "e08b42168c48248d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The API returns the response as a JSON object.\n",
    "\n",
    "The query output is available as a downloadable file, which you can download using the `download_url` field in the response, which you can load directly into Python as a pandas DataFrame object."
   ],
   "id": "931568f8e685ec92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T12:21:56.192703Z",
     "start_time": "2025-07-31T12:21:56.189122Z"
    }
   },
   "cell_type": "markdown",
   "source": "In Python, the whole pipeline consists of several steps:",
   "id": "167b1cc7ba087017"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:22:48.593748Z",
     "start_time": "2025-07-31T18:22:48.490009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (1) define the database connection\n",
    "api_url = \"https://ccs-lab.zcu.cz/grela-api/api/query\"\n",
    "# (2) define the query, e.g.:\n",
    "query = \"SELECT * FROM works\"\n",
    "# (3) execute the query via requests\n",
    "response = requests.post(api_url, json={\"query\": query})\n",
    "# (4) retrieve the download URL from the response with error checking\n",
    "download_url = response.json()[\"download_url\"]\n",
    "print(download_url)"
   ],
   "id": "e2fe75801ff8ff0a",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ccs-lab.zcu.cz/grela-api-out/a4209096-606a-4633-b03c-508a3c67830e.parquet\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:22:50.010025Z",
     "start_time": "2025-07-31T18:22:49.989758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (5) load the file object into a pandas DataFrame\n",
    "df = pd.read_parquet(download_url)\n",
    "len(df)"
   ],
   "id": "96c04d5cbd2d7b9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11117"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Working with the `works` table\n",
    "\n",
    "the `works` table contains all the metadata about the works in the database."
   ],
   "id": "1ceb795aed2d7742"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:22:51.742565Z",
     "start_time": "2025-07-31T18:22:51.619538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# you can easily obtain the entire `works` table as a pandas DataFrame\n",
    "query = \"SELECT * FROM works\"\n",
    "df = pd.read_parquet(requests.post(api_url, json={\"query\": query}).json()[\"download_url\"])"
   ],
   "id": "12ddb4d44ef67de1",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:22:52.480350Z",
     "start_time": "2025-07-31T18:22:52.410189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# you can also select specific works, for instance, based on the date columns:\n",
    "query = \"\"\"\n",
    "SELECT * FROM works as w\n",
    "WHERE (w.not_before > 100 AND w.not_before < 200)\n",
    "   OR (w.not_after > 100 AND w.not_after < 200);\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_parquet(requests.post(api_url, json={\"query\": query}).json()[\"download_url\"])\n",
    "df.head(5)"
   ],
   "id": "835e9c192ff1c071",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  grela_source             grela_id    author  \\\n",
       "0         lagt  lagt_ogl0001.ogl001   Pinytus   \n",
       "1         lagt  lagt_tlg0007.tlg001  Plutarch   \n",
       "2         lagt  lagt_tlg0007.tlg002  Plutarch   \n",
       "3         lagt  lagt_tlg0007.tlg003  Plutarch   \n",
       "4         lagt  lagt_tlg0007.tlg004  Plutarch   \n",
       "\n",
       "                             title  not_before  not_after  \\\n",
       "0  De Epistola Pinyti ad Dionysium       101.0      200.0   \n",
       "1                           Θησεύς        96.0      116.0   \n",
       "2                          Ῥωμύλος        96.0      116.0   \n",
       "3     Θησέως καὶ Ῥωμύλου σύγκρισις        96.0      116.0   \n",
       "4                        Λυκοῦργος        96.0      120.0   \n",
       "\n",
       "                   lagt_tlg_epithet lagt_genre lagt_provenience  \\\n",
       "0                                []         []        christian   \n",
       "1  ['Biographi' 'Philosophici/-ae']         []            pagan   \n",
       "2  ['Biographi' 'Philosophici/-ae']         []            pagan   \n",
       "3  ['Biographi' 'Philosophici/-ae']         []            pagan   \n",
       "4  ['Biographi' 'Philosophici/-ae']         []            pagan   \n",
       "\n",
       "  noscemus_place noscemus_genre noscemus_discipline title_short  \\\n",
       "0           None           None                None        None   \n",
       "1           None           None                None        None   \n",
       "2           None           None                None        None   \n",
       "3           None           None                None        None   \n",
       "4           None           None                None        None   \n",
       "\n",
       "   emlap_noscemus_id place_publication place_geonames  author_viaf  \\\n",
       "0                NaN              None           None          NaN   \n",
       "1                NaN              None           None          NaN   \n",
       "2                NaN              None           None          NaN   \n",
       "3                NaN              None           None          NaN   \n",
       "4                NaN              None           None          NaN   \n",
       "\n",
       "   title_viaf  date_random  token_count  \n",
       "0         NaN        135.0          109  \n",
       "1         NaN        110.0         8514  \n",
       "2         NaN         98.0        10668  \n",
       "3         NaN        106.0         1315  \n",
       "4         NaN        105.0        10933  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grela_source</th>\n",
       "      <th>grela_id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>not_before</th>\n",
       "      <th>not_after</th>\n",
       "      <th>lagt_tlg_epithet</th>\n",
       "      <th>lagt_genre</th>\n",
       "      <th>lagt_provenience</th>\n",
       "      <th>noscemus_place</th>\n",
       "      <th>noscemus_genre</th>\n",
       "      <th>noscemus_discipline</th>\n",
       "      <th>title_short</th>\n",
       "      <th>emlap_noscemus_id</th>\n",
       "      <th>place_publication</th>\n",
       "      <th>place_geonames</th>\n",
       "      <th>author_viaf</th>\n",
       "      <th>title_viaf</th>\n",
       "      <th>date_random</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_ogl0001.ogl001</td>\n",
       "      <td>Pinytus</td>\n",
       "      <td>De Epistola Pinyti ad Dionysium</td>\n",
       "      <td>101.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>christian</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg001</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Θησεύς</td>\n",
       "      <td>96.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>8514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg002</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Ῥωμύλος</td>\n",
       "      <td>96.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg003</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Θησέως καὶ Ῥωμύλου σύγκρισις</td>\n",
       "      <td>96.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lagt</td>\n",
       "      <td>lagt_tlg0007.tlg004</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Λυκοῦργος</td>\n",
       "      <td>96.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>['Biographi' 'Philosophici/-ae']</td>\n",
       "      <td>[]</td>\n",
       "      <td>pagan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.0</td>\n",
       "      <td>10933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:22:59.488399Z",
     "start_time": "2025-07-31T18:22:57.070695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# to get a quick overview of the subcorpora, including the work counts, sentence counts and token counts\n",
    "query = \"\"\"\n",
    "WITH subcorpora AS (\n",
    "    SELECT\n",
    "        SUBSTR(grela_id, 0, INSTR(grela_id, '_')) AS subcorpus,\n",
    "        COUNT(DISTINCT grela_id) AS works_N,\n",
    "        COUNT(DISTINCT sentence_id) AS sentences_N,\n",
    "        COUNT(*) AS tokens_N\n",
    "    FROM tokens\n",
    "    GROUP BY subcorpus\n",
    ")\n",
    "SELECT * FROM subcorpora\n",
    "ORDER BY subcorpus;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch as a pandas DataFrame\n",
    "subcorpus_stats_df = pd.read_parquet(requests.post(api_url, json={\"query\": query}).json()[\"download_url\"])\n",
    "subcorpus_stats_df"
   ],
   "id": "650b268972892c4b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  subcorpus  works_N  sentences_N   tokens_N\n",
       "0        cc     7819     11834607  201909639\n",
       "1     emlap       73       220846    3495212\n",
       "2      lagt     1957      2703678   35808742\n",
       "3  noscemus      996     11802783  139401899\n",
       "4   vulgate       73        35254     603091"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcorpus</th>\n",
       "      <th>works_N</th>\n",
       "      <th>sentences_N</th>\n",
       "      <th>tokens_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc</td>\n",
       "      <td>7819</td>\n",
       "      <td>11834607</td>\n",
       "      <td>201909639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emlap</td>\n",
       "      <td>73</td>\n",
       "      <td>220846</td>\n",
       "      <td>3495212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lagt</td>\n",
       "      <td>1957</td>\n",
       "      <td>2703678</td>\n",
       "      <td>35808742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noscemus</td>\n",
       "      <td>996</td>\n",
       "      <td>11802783</td>\n",
       "      <td>139401899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vulgate</td>\n",
       "      <td>73</td>\n",
       "      <td>35254</td>\n",
       "      <td>603091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Working with the `sentences` table",
   "id": "4268b44ba611fdb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:23:01.843898Z",
     "start_time": "2025-07-31T18:23:01.645268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extract a subset of sentences with work level metadata, select on specific grela_id pattern\n",
    "query = \"\"\"\n",
    "        SELECT s.grela_id,\n",
    "               s.sentence_id,\n",
    "               s.text,\n",
    "               w.*\n",
    "        FROM sentences s\n",
    "                 JOIN works w ON s.grela_id = w.grela_id\n",
    "        WHERE w.grela_id LIKE 'vulgate_%' \\\n",
    "        \"\"\"\n",
    "\n",
    "vulgate_sentences = pd.read_parquet(requests.post(api_url, json={\"query\": query}).json()[\"download_url\"])"
   ],
   "id": "8d61a47898b2936f",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:23:02.424056Z",
     "start_time": "2025-07-31T18:23:02.414344Z"
    }
   },
   "cell_type": "code",
   "source": "vulgate_sentences.head(5)",
   "id": "965d7e53ad82676b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         grela_id                         sentence_id  \\\n",
       "0  vulgate_tlg0031.tlg001.obi-lat  vulgate_tlg0031.tlg001.obi-lat:1.1   \n",
       "1  vulgate_tlg0031.tlg001.obi-lat  vulgate_tlg0031.tlg001.obi-lat:1.2   \n",
       "2  vulgate_tlg0031.tlg001.obi-lat  vulgate_tlg0031.tlg001.obi-lat:1.3   \n",
       "3  vulgate_tlg0031.tlg001.obi-lat  vulgate_tlg0031.tlg001.obi-lat:1.4   \n",
       "4  vulgate_tlg0031.tlg001.obi-lat  vulgate_tlg0031.tlg001.obi-lat:1.5   \n",
       "\n",
       "                                                text grela_source  \\\n",
       "0  liber generationis Iesu Christi filii David fi...      vulgate   \n",
       "1  Abraham genuit Isaac Isaac autem genuit Iacob ...      vulgate   \n",
       "2  Iudas autem genuit Phares et Zara de Thamar Ph...      vulgate   \n",
       "3  Aram autem genuit Aminadab Aminadab autem genu...      vulgate   \n",
       "4  Salmon autem genuit Booz de Rachab Booz autem ...      vulgate   \n",
       "\n",
       "                       grela_id_1 author              title  not_before  \\\n",
       "0  vulgate_tlg0031.tlg001.obi-lat   None  Vulgate - Matthew         NaN   \n",
       "1  vulgate_tlg0031.tlg001.obi-lat   None  Vulgate - Matthew         NaN   \n",
       "2  vulgate_tlg0031.tlg001.obi-lat   None  Vulgate - Matthew         NaN   \n",
       "3  vulgate_tlg0031.tlg001.obi-lat   None  Vulgate - Matthew         NaN   \n",
       "4  vulgate_tlg0031.tlg001.obi-lat   None  Vulgate - Matthew         NaN   \n",
       "\n",
       "   not_after lagt_tlg_epithet lagt_genre lagt_provenience noscemus_place  \\\n",
       "0        NaN             None       None             None           None   \n",
       "1        NaN             None       None             None           None   \n",
       "2        NaN             None       None             None           None   \n",
       "3        NaN             None       None             None           None   \n",
       "4        NaN             None       None             None           None   \n",
       "\n",
       "  noscemus_genre noscemus_discipline title_short  emlap_noscemus_id  \\\n",
       "0           None                None        None                NaN   \n",
       "1           None                None        None                NaN   \n",
       "2           None                None        None                NaN   \n",
       "3           None                None        None                NaN   \n",
       "4           None                None        None                NaN   \n",
       "\n",
       "  place_publication place_geonames  author_viaf  title_viaf  date_random  \\\n",
       "0              None           None          NaN         NaN          NaN   \n",
       "1              None           None          NaN         NaN          NaN   \n",
       "2              None           None          NaN         NaN          NaN   \n",
       "3              None           None          NaN         NaN          NaN   \n",
       "4              None           None          NaN         NaN          NaN   \n",
       "\n",
       "   token_count  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grela_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>grela_source</th>\n",
       "      <th>grela_id_1</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>not_before</th>\n",
       "      <th>not_after</th>\n",
       "      <th>lagt_tlg_epithet</th>\n",
       "      <th>lagt_genre</th>\n",
       "      <th>lagt_provenience</th>\n",
       "      <th>noscemus_place</th>\n",
       "      <th>noscemus_genre</th>\n",
       "      <th>noscemus_discipline</th>\n",
       "      <th>title_short</th>\n",
       "      <th>emlap_noscemus_id</th>\n",
       "      <th>place_publication</th>\n",
       "      <th>place_geonames</th>\n",
       "      <th>author_viaf</th>\n",
       "      <th>title_viaf</th>\n",
       "      <th>date_random</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat:1.1</td>\n",
       "      <td>liber generationis Iesu Christi filii David fi...</td>\n",
       "      <td>vulgate</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>None</td>\n",
       "      <td>Vulgate - Matthew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat:1.2</td>\n",
       "      <td>Abraham genuit Isaac Isaac autem genuit Iacob ...</td>\n",
       "      <td>vulgate</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>None</td>\n",
       "      <td>Vulgate - Matthew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat:1.3</td>\n",
       "      <td>Iudas autem genuit Phares et Zara de Thamar Ph...</td>\n",
       "      <td>vulgate</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>None</td>\n",
       "      <td>Vulgate - Matthew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat:1.4</td>\n",
       "      <td>Aram autem genuit Aminadab Aminadab autem genu...</td>\n",
       "      <td>vulgate</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>None</td>\n",
       "      <td>Vulgate - Matthew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat:1.5</td>\n",
       "      <td>Salmon autem genuit Booz de Rachab Booz autem ...</td>\n",
       "      <td>vulgate</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>None</td>\n",
       "      <td>Vulgate - Matthew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Working with the `tokens` table\n",
    "\n",
    "We can get all tokens data based on a specific work attribute, e.g. author name pattern\n",
    "\n",
    "In the example below, we select all tokens belonging to works by Plato.\n",
    "\n",
    "The tokens are in the order as they appear in the text, so you use this output to compile the text.\n",
    "\n",
    "You can also filter the tokens based on their POS tags, e.g. nouns, adjectives, etc.\n",
    "\n",
    "We also keep track of the `sentence_id`, so you can at any time retrieve the raw text of the sentence text from the `sentences` table."
   ],
   "id": "b8fd7fdc45e796bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:23:06.876011Z",
     "start_time": "2025-07-31T18:23:03.125701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "    SELECT t.*, w.*\n",
    "    FROM tokens t\n",
    "    JOIN works w ON t.grela_id = w.grela_id\n",
    "    WHERE w.author LIKE 'Plato'\n",
    "\"\"\"\n",
    "\n",
    "plato_tokens = pd.read_parquet(requests.post(api_url, json={\"query\": query}).json()[\"download_url\"])\n",
    "len(plato_tokens)"
   ],
   "id": "d00d2f1fa57df949",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379783"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:23:29.601526Z",
     "start_time": "2025-07-31T18:23:28.571850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# below we retrieve the raw text of all sentences containing the lemma \"labyrinthus\"\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    t.sentence_id,\n",
    "    t.grela_id,\n",
    "    t.token_id AS target_token_id,\n",
    "    t.char_start AS target_char_start,\n",
    "    t.char_end AS target_char_end,\n",
    "    s.text AS sentence_text,\n",
    "    w.author,\n",
    "    w.title,\n",
    "    w.not_before,\n",
    "    w.not_after\n",
    "FROM tokens t\n",
    "JOIN sentences s ON t.sentence_id = s.sentence_id\n",
    "JOIN works w ON t.grela_id = w.grela_id\n",
    "WHERE t.lemma = 'labyrinthus'\n",
    "\"\"\"\n",
    "\n",
    "target_sentences  = pd.read_parquet(requests.post(api_url, json={\"query\": query}).json()[\"download_url\"])\n",
    "target_sentences.head(5)"
   ],
   "id": "85a3576768a0fc16",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             sentence_id         grela_id  target_token_id  target_char_start  \\\n",
       "0      noscemus_605285_6  noscemus_605285         34285288                 91   \n",
       "1   noscemus_914304_6629  noscemus_914304         34503897               1253   \n",
       "2  noscemus_786344_21148  noscemus_786344         73757811                137   \n",
       "3  noscemus_786344_25714  noscemus_786344         73832879                 70   \n",
       "4          cc_12765_1477         cc_12765        236733163                 48   \n",
       "\n",
       "   target_char_end                                      sentence_text  \\\n",
       "0              101  sine istarum cognitione nec uerbum quidem inte...   \n",
       "1             1264  Nidus formicarum niger ex siluestribus de men ...   \n",
       "2              147  Uerum quidem est multos inesse maeandros obliq...   \n",
       "3               80  Istic uespertiliones erant a nostris, & ab iis...   \n",
       "4               58  Quid faciamus homines miserrimi et noui generi...   \n",
       "\n",
       "                    author                                              title  \\\n",
       "0  Cappeller, Moritz Anton  Prodromus crystallographiae: de crystallis imp...   \n",
       "1    Rumpf, Georg Eberhard  Herbarium Amboinense, plurimas complectens arb...   \n",
       "2     L'Ecluse, Charles de  Exoticorum libri decem: quibus animalium, plan...   \n",
       "3     L'Ecluse, Charles de  Exoticorum libri decem: quibus animalium, plan...   \n",
       "4                Petronius                   Satyricon, Fragmenta, et Poemata   \n",
       "\n",
       "   not_before  not_after  \n",
       "0      1723.0     1723.0  \n",
       "1      1741.0     1750.0  \n",
       "2      1605.0     1605.0  \n",
       "3      1605.0     1605.0  \n",
       "4        14.0       66.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>grela_id</th>\n",
       "      <th>target_token_id</th>\n",
       "      <th>target_char_start</th>\n",
       "      <th>target_char_end</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>not_before</th>\n",
       "      <th>not_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noscemus_605285_6</td>\n",
       "      <td>noscemus_605285</td>\n",
       "      <td>34285288</td>\n",
       "      <td>91</td>\n",
       "      <td>101</td>\n",
       "      <td>sine istarum cognitione nec uerbum quidem inte...</td>\n",
       "      <td>Cappeller, Moritz Anton</td>\n",
       "      <td>Prodromus crystallographiae: de crystallis imp...</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>1723.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noscemus_914304_6629</td>\n",
       "      <td>noscemus_914304</td>\n",
       "      <td>34503897</td>\n",
       "      <td>1253</td>\n",
       "      <td>1264</td>\n",
       "      <td>Nidus formicarum niger ex siluestribus de men ...</td>\n",
       "      <td>Rumpf, Georg Eberhard</td>\n",
       "      <td>Herbarium Amboinense, plurimas complectens arb...</td>\n",
       "      <td>1741.0</td>\n",
       "      <td>1750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noscemus_786344_21148</td>\n",
       "      <td>noscemus_786344</td>\n",
       "      <td>73757811</td>\n",
       "      <td>137</td>\n",
       "      <td>147</td>\n",
       "      <td>Uerum quidem est multos inesse maeandros obliq...</td>\n",
       "      <td>L'Ecluse, Charles de</td>\n",
       "      <td>Exoticorum libri decem: quibus animalium, plan...</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>1605.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noscemus_786344_25714</td>\n",
       "      <td>noscemus_786344</td>\n",
       "      <td>73832879</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>Istic uespertiliones erant a nostris, &amp; ab iis...</td>\n",
       "      <td>L'Ecluse, Charles de</td>\n",
       "      <td>Exoticorum libri decem: quibus animalium, plan...</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>1605.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cc_12765_1477</td>\n",
       "      <td>cc_12765</td>\n",
       "      <td>236733163</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>Quid faciamus homines miserrimi et noui generi...</td>\n",
       "      <td>Petronius</td>\n",
       "      <td>Satyricon, Fragmenta, et Poemata</td>\n",
       "      <td>14.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:25:23.639185Z",
     "start_time": "2025-07-31T18:24:50.083237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract token data from all sentences containing the lemma \"liber\" with the POS tag \"NOUN\"\n",
    "\n",
    "query = \"\"\"\n",
    "WITH target_matches AS (\n",
    "    SELECT sentence_id\n",
    "    FROM tokens t\n",
    "    WHERE t.lemma = 'liber' AND t.pos IN ('NOUN')\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    sentence_id,\n",
    "    LIST(\n",
    "        STRUCT_PACK(\n",
    "            token_id    := token_id,\n",
    "            token_text  := token_text,\n",
    "            lemma       := lemma,\n",
    "            pos         := pos,\n",
    "            char_start  := char_start,\n",
    "            char_end    := char_end,\n",
    "            sentence_id := sentence_id\n",
    "        )\n",
    "        ORDER BY token_id\n",
    "    ) AS tokens\n",
    "FROM tokens\n",
    "WHERE sentence_id IN (SELECT DISTINCT sentence_id FROM target_matches)\n",
    "GROUP BY sentence_id;\n",
    "\"\"\"\n",
    "\n",
    "target_sentences_token_data  = pd.read_parquet(requests.post(api_url, json={\"query\": query}).json()[\"download_url\"])\n",
    "target_sentences_token_data.head(5)\n"
   ],
   "id": "f169623447816538",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:25:28.647150Z",
     "start_time": "2025-07-31T18:25:28.639607Z"
    }
   },
   "cell_type": "code",
   "source": "target_sentences_token_data.head(5)",
   "id": "b1fcc28dbd0b989a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         sentence_id                                             tokens\n",
       "0    emlap_100061_88  [{'char_end': 11, 'char_start': 0, 'lemma': 'h...\n",
       "1   emlap_100061_458  [{'char_end': 3, 'char_start': 0, 'lemma': 'li...\n",
       "2   emlap_100061_539  [{'char_end': 3, 'char_start': 0, 'lemma': 'li...\n",
       "3  emlap_100061_1287  [{'char_end': 1, 'char_start': 0, 'lemma': '&'...\n",
       "4  emlap_100061_2320  [{'char_end': 3, 'char_start': 0, 'lemma': 'li..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emlap_100061_88</td>\n",
       "      <td>[{'char_end': 11, 'char_start': 0, 'lemma': 'h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emlap_100061_458</td>\n",
       "      <td>[{'char_end': 3, 'char_start': 0, 'lemma': 'li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emlap_100061_539</td>\n",
       "      <td>[{'char_end': 3, 'char_start': 0, 'lemma': 'li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emlap_100061_1287</td>\n",
       "      <td>[{'char_end': 1, 'char_start': 0, 'lemma': '&amp;'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emlap_100061_2320</td>\n",
       "      <td>[{'char_end': 3, 'char_start': 0, 'lemma': 'li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can also retrieve the token data for a subset of works, like for all Christian works from the first three centuries",
   "id": "d026627dea7c1c0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T17:55:00.496776Z",
     "start_time": "2025-07-31T17:54:45.855716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### all token data from sentences with lagt_provenience \"christian\" and \"not_ and not_after intersecting the first three centuries\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    t.sentence_id,\n",
    "    w.author,\n",
    "    w.title,\n",
    "    w.not_before,\n",
    "    w.not_after,\n",
    "    LIST(\n",
    "        STRUCT_PACK(\n",
    "            token_id    := t.token_id,\n",
    "            token_text  := t.token_text,\n",
    "            lemma       := t.lemma,\n",
    "            pos         := t.pos,\n",
    "            char_start  := t.char_start,\n",
    "            char_end    := t.char_end,\n",
    "            sentence_id := t.sentence_id\n",
    "        )\n",
    "        ORDER BY t.token_id\n",
    "    ) AS tokens\n",
    "FROM tokens t\n",
    "JOIN works w ON t.grela_id = w.grela_id\n",
    "WHERE w.lagt_provenience = 'christian'\n",
    "  AND w.not_before >= 0 AND w.not_before < 300\n",
    "  AND w.not_after  >= 0 AND w.not_after  < 300\n",
    "GROUP BY t.sentence_id, w.author, w.title, w.not_before, w.not_after\n",
    "\"\"\"\n",
    "\n",
    "EC_sentence_tokens = pd.read_parquet(requests.post(api_url, json={\"query\": query}).json()[\"download_url\"])\n",
    "len(EC_sentence_tokens)"
   ],
   "id": "6696a055d86bb47b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156571"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "From this output you can easily get to the data format we used previously in the LAGT dataset and elsewhere for training distributional semantic models.",
   "id": "76341286dbac1a98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:01:03.564793Z",
     "start_time": "2025-07-31T18:01:02.891542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EC_sentence_tokens[\"lemmatized_sentence\"] = EC_sentence_tokens[\"tokens\"].apply(lambda x: [t[\"lemma\"] for t in x if t[\"pos\"] in [\"n\", \"v\", \"a\"]])\n",
    "EC_sentence_tokens[\"lemmatized_sentence\"].tolist()[:10]"
   ],
   "id": "d4251b5ea94235f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['σύνειμι', 'λογισμός', 'οἶδα', 'ἀρχή', 'λαμβάνω'],\n",
       " ['τίς', 'νοέω', 'δυνατός'],\n",
       " ['ὠχριακότα', 'τήκομαι'],\n",
       " ['βούλομαι', 'φθάνω', 'λέγω'],\n",
       " ['λέγω'],\n",
       " [],\n",
       " ['συνεβέλευέν', 'οὗτς', 'τολμάω', 'πολύς', 'τρόπες'],\n",
       " ['λογισμός',\n",
       "  'πρᾶγμα',\n",
       "  'φήμη',\n",
       "  'τιβερίς',\n",
       "  'καῖσαρ',\n",
       "  'βασιλεία',\n",
       "  'ἐαρινός',\n",
       "  'τροπή',\n",
       "  'ἀρχή',\n",
       "  'λαμβάνεσα',\n",
       "  'ἤυξανεν',\n",
       "  'ἀγαθός',\n",
       "  'θεός',\n",
       "  'ἄγγελος',\n",
       "  'διέρχομαι',\n",
       "  'κόσμος',\n",
       "  'θεός',\n",
       "  'βούλημα',\n",
       "  'σιγάω',\n",
       "  'στέγω',\n",
       "  'δύναμαι'],\n",
       " ['ἀπειθήω', 'ψυχή', 'σῶμα', 'λύσις', 'τόπος', 'πῦρ', 'βληθήσω'],\n",
       " []]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c1496e8e45e7baca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You can ultimately run very complex queries using the API.\n",
    "\n",
    "In the example below, we retrieve the contextual data for all tokens matching the lemma \"liber\" with the POS tag \"NOUN\".\n",
    "\n",
    "For each token, we retrieve:\n",
    "- (1) the raw sentence in which the (lemmatized) token appears (`semtence_tokens`),\n",
    "- (2) the token data from the sentence in which the token appears (`sentence_tokens`),\n",
    "- (3) a broader context, including also 1 raw sentence before and 1 raw sentence after the target token (`context_3sents`)\n",
    "- (4) concordance from the 10 tokens preceding and 10 tokens following the target token (i.e. 10+1+10 tokens) (`concordance_tokens`).\n",
    "\n",
    "All these co-occurrence data are then returned within a single table and can be used for different kinds of co-occurrence and semantic analyses."
   ],
   "id": "bcb8dc8272114586"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:27:01.127698Z",
     "start_time": "2025-07-31T18:27:01.122128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def get_grouped_token_data_with_metadata_api(api_url: str, lemma: str, pos_tags: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    API version of grouped token query with context and metadata.\n",
    "    \"\"\"\n",
    "    pos_placeholder = \", \".join(f\"'{tag}'\" for tag in pos_tags)\n",
    "    lemma_literal = lemma.replace(\"'\", \"''\")  # SQL-safe single quotes\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH target_matches AS (\n",
    "        SELECT\n",
    "            t.sentence_id,\n",
    "            t.grela_id,\n",
    "            s.position AS sentence_position,\n",
    "            t.token_id AS target_token_id,\n",
    "            t.char_start AS target_char_start,\n",
    "            t.char_end AS target_char_end\n",
    "        FROM tokens t\n",
    "        JOIN sentences s USING (sentence_id)\n",
    "        WHERE t.lemma = '{lemma_literal}'\n",
    "        AND t.pos IN ({pos_placeholder})\n",
    "    ),\n",
    "\n",
    "    context_3sents AS (\n",
    "        SELECT\n",
    "            tm.sentence_id,\n",
    "            STRING_AGG(s.text, ' | ' ORDER BY s.position) AS context_3sents\n",
    "        FROM target_matches tm\n",
    "        JOIN sentences s\n",
    "          ON s.grela_id = tm.grela_id\n",
    "         AND s.position BETWEEN tm.sentence_position - 1\n",
    "                            AND tm.sentence_position + 1\n",
    "        GROUP BY tm.sentence_id\n",
    "    ),\n",
    "\n",
    "    sentence_tokens AS (\n",
    "        SELECT\n",
    "            sentence_id,\n",
    "            LIST(\n",
    "              STRUCT_PACK(\n",
    "                 token_id := token_id,\n",
    "                 token_text := token_text,\n",
    "                 lemma := lemma,\n",
    "                 pos := pos,\n",
    "                 char_start := char_start,\n",
    "                 char_end := char_end,\n",
    "                 sentence_id := sentence_id\n",
    "              )\n",
    "              ORDER BY token_id\n",
    "            ) AS tokens\n",
    "        FROM tokens\n",
    "        WHERE sentence_id IN (SELECT DISTINCT sentence_id FROM target_matches)\n",
    "        GROUP BY sentence_id\n",
    "    ),\n",
    "\n",
    "    concordance_tokens AS (\n",
    "        SELECT\n",
    "            tm.sentence_id,\n",
    "            tm.target_token_id,\n",
    "            LIST(\n",
    "              STRUCT_PACK(\n",
    "                 token_id := ct.token_id,\n",
    "                 token_text := ct.token_text,\n",
    "                 lemma := ct.lemma,\n",
    "                 pos := ct.pos,\n",
    "                 char_start := ct.char_start,\n",
    "                 char_end := ct.char_end,\n",
    "                 sentence_id := ct.sentence_id\n",
    "              )\n",
    "              ORDER BY ct.token_id\n",
    "            ) AS concordance_tokens\n",
    "        FROM target_matches tm\n",
    "        JOIN tokens ct\n",
    "          ON ct.grela_id = tm.grela_id\n",
    "         AND ct.token_id BETWEEN tm.target_token_id - 10\n",
    "                            AND tm.target_token_id + 10\n",
    "        GROUP BY tm.sentence_id, tm.target_token_id\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "        w.author,\n",
    "        w.title,\n",
    "        tm.grela_id,\n",
    "        tm.sentence_id,\n",
    "        s.text AS sentence_text,\n",
    "        c3.context_3sents,\n",
    "        st.tokens,\n",
    "        ct.concordance_tokens,\n",
    "        w.not_before,\n",
    "        w.not_after,\n",
    "        w.date_random,\n",
    "        w.lagt_genre,\n",
    "        w.lagt_provenience,\n",
    "        w.noscemus_genre,\n",
    "        w.noscemus_discipline,\n",
    "        tm.target_token_id,\n",
    "        tm.target_char_start,\n",
    "        tm.target_char_end\n",
    "    FROM target_matches tm\n",
    "    JOIN sentences s USING (sentence_id)\n",
    "    JOIN works w ON w.grela_id = tm.grela_id\n",
    "    LEFT JOIN context_3sents c3 USING (sentence_id)\n",
    "    LEFT JOIN sentence_tokens st USING (sentence_id)\n",
    "    LEFT JOIN concordance_tokens ct\n",
    "           ON ct.sentence_id = tm.sentence_id\n",
    "          AND ct.target_token_id = tm.target_token_id\n",
    "    ORDER BY tm.sentence_id, tm.target_token_id;\n",
    "    \"\"\"\n",
    "\n",
    "    # Send query to the API\n",
    "    response = requests.post(api_url, json={\"query\": query})\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Load the result\n",
    "    download_url = response.json()[\"download_url\"]\n",
    "    return pd.read_parquet(download_url)"
   ],
   "id": "7151bf43f069cfa2",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:49:07.256776Z",
     "start_time": "2025-07-31T18:47:34.831097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Example usage\n",
    "liber_contextual_data = get_grouped_token_data_with_metadata_api(\n",
    "    api_url=\"https://ccs-lab.zcu.cz/grela-api/api/query\",\n",
    "    lemma=\"liber\",\n",
    "    pos_tags=[\"NOUN\"])"
   ],
   "id": "6a1a227767631a15",
   "execution_count": 72,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:52:24.278892Z",
     "start_time": "2025-07-31T18:52:24.275149Z"
    }
   },
   "cell_type": "code",
   "source": "len(liber_contextual_data)",
   "id": "7446d6a0543d820b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303829"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T18:58:19.022307Z",
     "start_time": "2025-07-31T18:58:18.986342Z"
    }
   },
   "cell_type": "code",
   "source": "liber_contextual_data.head()",
   "id": "981daba2c530e1f0",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               author                  title  grela_id  sentence_id  \\\n",
       "0  Franco Leodiensis   De quadratura circuli  cc_10000  cc_10000_12   \n",
       "1  Franco Leodiensis   De quadratura circuli  cc_10000  cc_10000_12   \n",
       "2  Franco Leodiensis   De quadratura circuli  cc_10000  cc_10000_14   \n",
       "3  Franco Leodiensis   De quadratura circuli  cc_10000  cc_10000_38   \n",
       "4  Franco Leodiensis   De quadratura circuli  cc_10000   cc_10000_4   \n",
       "\n",
       "                                       sentence_text  \\\n",
       "0  En autem partem prologi ad primum librum, item...   \n",
       "1  En autem partem prologi ad primum librum, item...   \n",
       "2  Incipit Prologus In Primum Librum Domni Franco...   \n",
       "3  Uirgilius cupiens a parentibus magnificare Aug...   \n",
       "4  Amatores scientiae saecularis taxent ejus scie...   \n",
       "\n",
       "                                      context_3sents  \\\n",
       "0  unde satis liquet Franconis opus intra hoc tem...   \n",
       "1  unde satis liquet Franconis opus intra hoc tem...   \n",
       "2  hos enim locos ad specimen praebendum delegi, ...   \n",
       "3  Si tu is esses, praesul eximie, cujus suae lau...   \n",
       "4  Sic igitur Sigebertus, cap. 164. << Franco Sch...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [{'char_end': 2, 'char_start': 0, 'lemma': 'in...   \n",
       "1  [{'char_end': 2, 'char_start': 0, 'lemma': 'in...   \n",
       "2  [{'char_end': 7, 'char_start': 0, 'lemma': 'in...   \n",
       "3  [{'char_end': 9, 'char_start': 0, 'lemma': 'ui...   \n",
       "4  [{'char_end': 8, 'char_start': 0, 'lemma': 'am...   \n",
       "\n",
       "                                  concordance_tokens  not_before  not_after  \\\n",
       "0  [{'char_end': 59, 'char_start': 52, 'lemma': '...         NaN        NaN   \n",
       "1  [{'char_end': 26, 'char_start': 24, 'lemma': '...         NaN        NaN   \n",
       "2  [{'char_end': 50, 'char_start': 46, 'lemma': '...         NaN        NaN   \n",
       "3  [{'char_end': 437, 'char_start': 436, 'lemma':...         NaN        NaN   \n",
       "4  [{'char_end': 158, 'char_start': 147, 'lemma':...         NaN        NaN   \n",
       "\n",
       "   date_random lagt_genre lagt_provenience noscemus_genre noscemus_discipline  \\\n",
       "0          NaN       None             None           None                None   \n",
       "1          NaN       None             None           None                None   \n",
       "2          NaN       None             None           None                None   \n",
       "3          NaN       None             None           None                None   \n",
       "4          NaN       None             None           None                None   \n",
       "\n",
       "   target_token_id  target_char_start  target_char_end  \n",
       "0        248829267                 34               40  \n",
       "1        248829275                 73               78  \n",
       "2        248829298                 27               33  \n",
       "3        248829889                 65               71  \n",
       "4        248829141                 55               60  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>grela_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>context_3sents</th>\n",
       "      <th>tokens</th>\n",
       "      <th>concordance_tokens</th>\n",
       "      <th>not_before</th>\n",
       "      <th>not_after</th>\n",
       "      <th>date_random</th>\n",
       "      <th>lagt_genre</th>\n",
       "      <th>lagt_provenience</th>\n",
       "      <th>noscemus_genre</th>\n",
       "      <th>noscemus_discipline</th>\n",
       "      <th>target_token_id</th>\n",
       "      <th>target_char_start</th>\n",
       "      <th>target_char_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Franco Leodiensis</td>\n",
       "      <td>De quadratura circuli</td>\n",
       "      <td>cc_10000</td>\n",
       "      <td>cc_10000_12</td>\n",
       "      <td>En autem partem prologi ad primum librum, item...</td>\n",
       "      <td>unde satis liquet Franconis opus intra hoc tem...</td>\n",
       "      <td>[{'char_end': 2, 'char_start': 0, 'lemma': 'in...</td>\n",
       "      <td>[{'char_end': 59, 'char_start': 52, 'lemma': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>248829267</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Franco Leodiensis</td>\n",
       "      <td>De quadratura circuli</td>\n",
       "      <td>cc_10000</td>\n",
       "      <td>cc_10000_12</td>\n",
       "      <td>En autem partem prologi ad primum librum, item...</td>\n",
       "      <td>unde satis liquet Franconis opus intra hoc tem...</td>\n",
       "      <td>[{'char_end': 2, 'char_start': 0, 'lemma': 'in...</td>\n",
       "      <td>[{'char_end': 26, 'char_start': 24, 'lemma': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>248829275</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Franco Leodiensis</td>\n",
       "      <td>De quadratura circuli</td>\n",
       "      <td>cc_10000</td>\n",
       "      <td>cc_10000_14</td>\n",
       "      <td>Incipit Prologus In Primum Librum Domni Franco...</td>\n",
       "      <td>hos enim locos ad specimen praebendum delegi, ...</td>\n",
       "      <td>[{'char_end': 7, 'char_start': 0, 'lemma': 'in...</td>\n",
       "      <td>[{'char_end': 50, 'char_start': 46, 'lemma': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>248829298</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Franco Leodiensis</td>\n",
       "      <td>De quadratura circuli</td>\n",
       "      <td>cc_10000</td>\n",
       "      <td>cc_10000_38</td>\n",
       "      <td>Uirgilius cupiens a parentibus magnificare Aug...</td>\n",
       "      <td>Si tu is esses, praesul eximie, cujus suae lau...</td>\n",
       "      <td>[{'char_end': 9, 'char_start': 0, 'lemma': 'ui...</td>\n",
       "      <td>[{'char_end': 437, 'char_start': 436, 'lemma':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>248829889</td>\n",
       "      <td>65</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Franco Leodiensis</td>\n",
       "      <td>De quadratura circuli</td>\n",
       "      <td>cc_10000</td>\n",
       "      <td>cc_10000_4</td>\n",
       "      <td>Amatores scientiae saecularis taxent ejus scie...</td>\n",
       "      <td>Sic igitur Sigebertus, cap. 164. &lt;&lt; Franco Sch...</td>\n",
       "      <td>[{'char_end': 8, 'char_start': 0, 'lemma': 'am...</td>\n",
       "      <td>[{'char_end': 158, 'char_start': 147, 'lemma':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>248829141</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "378d59523747e0c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
