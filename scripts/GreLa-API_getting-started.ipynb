{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T12:14:30.830804Z",
     "start_time": "2025-07-31T12:14:30.827211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import os\n",
    "import os, json\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)"
   ],
   "id": "10a1a40addaefa80",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:02:05.617680Z",
     "start_time": "2025-07-31T13:02:05.614524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the database is available on the following endpoint:\n",
    "api_url = \"https://ccs-lab.zcu.cz/grela-api/api/query\""
   ],
   "id": "d4432ae5315a43ab",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The database is publicly available online from the following endpoint:\n",
    "\n",
    "```bash\n",
    "https://ccs-lab.zcu.cz/grela-api/api/query\n",
    "```\n",
    "\n",
    "Through the API, you can query it using the same queries as the local version.\n",
    "\n",
    "For instance, to retrieve the first 10 rows from  the `works` table, your SQL query would be:\n",
    "```\n",
    "SELECT * FROM works LIMIT 10;\n",
    "```\n",
    "\n",
    "To execute the query from the command line, you could use the `curl` command, e.g.:\n",
    "```bash\n",
    "curl -X POST https://ccs-lab.zcu.cz/grela-api/api/query \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"query\": \"SELECT * FROM works\", \"format\": \"json\"}'\n",
    "```"
   ],
   "id": "e08b42168c48248d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "The API returns the response as a JSON object.\n",
    "\n",
    "The query output is available as a downloadable file, which you can download using the `download_url` field in the response, which you can load directly into Python as a pandas DataFrame object."
   ],
   "id": "931568f8e685ec92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T12:21:56.192703Z",
     "start_time": "2025-07-31T12:21:56.189122Z"
    }
   },
   "cell_type": "markdown",
   "source": "In Python, the whole pipeline consists of several steps:",
   "id": "167b1cc7ba087017"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:02:08.355264Z",
     "start_time": "2025-07-31T13:02:08.255744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (1) define the database connection\n",
    "api_url = \"https://ccs-lab.zcu.cz/grela-api/api/query\"\n",
    "# (2) define the query, e.g.:\n",
    "query = \"SELECT * FROM works\"\n",
    "# (3) execute the query via requests\n",
    "response = requests.post(api_url, json={\"query\": query})\n",
    "# (4) retrieve the download URL from the response with error checking\n",
    "download_url = response.json()[\"download_url\"]\n",
    "print(download_url)"
   ],
   "id": "e2fe75801ff8ff0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ccs-lab.zcu.cz/grela-api-out/a0054855-5e9d-4518-b56a-d0971443a10d.parquet\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:02:10.168226Z",
     "start_time": "2025-07-31T13:02:10.147214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# (5) load the file object into a pandas DataFrame\n",
    "df = pd.read_parquet(download_url)\n",
    "len(df)"
   ],
   "id": "96c04d5cbd2d7b9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11117"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:02:11.028931Z",
     "start_time": "2025-07-31T13:02:10.906129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# you can easily make it more condensed like this:\n",
    "query = \"SELECT * FROM works\"\n",
    "df = pd.read_parquet(requests.post(api_url, json={\"query\": query}).json()[\"download_url\"])"
   ],
   "id": "12ddb4d44ef67de1",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:02:11.855692Z",
     "start_time": "2025-07-31T13:02:11.584145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extract a subset of sentences with work level metadata, select on specific grela_id pattern\n",
    "query = \"\"\"\n",
    "        SELECT s.grela_id,\n",
    "               s.sentence_id,\n",
    "               s.text,\n",
    "               w.*\n",
    "        FROM sentences s\n",
    "                 JOIN works w ON s.grela_id = w.grela_id\n",
    "        WHERE w.grela_id LIKE 'vulgate_%' \\\n",
    "        \"\"\"\n",
    "\n",
    "vulgate_sentences = pd.read_parquet(requests.post(api_url, json={\"query\": query}).json()[\"download_url\"])"
   ],
   "id": "8d61a47898b2936f",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T13:02:12.527254Z",
     "start_time": "2025-07-31T13:02:12.516745Z"
    }
   },
   "cell_type": "code",
   "source": "vulgate_sentences.head(5)",
   "id": "965d7e53ad82676b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         grela_id                         sentence_id  \\\n",
       "0  vulgate_tlg0031.tlg001.obi-lat  vulgate_tlg0031.tlg001.obi-lat:1.1   \n",
       "1  vulgate_tlg0031.tlg001.obi-lat  vulgate_tlg0031.tlg001.obi-lat:1.2   \n",
       "2  vulgate_tlg0031.tlg001.obi-lat  vulgate_tlg0031.tlg001.obi-lat:1.3   \n",
       "3  vulgate_tlg0031.tlg001.obi-lat  vulgate_tlg0031.tlg001.obi-lat:1.4   \n",
       "4  vulgate_tlg0031.tlg001.obi-lat  vulgate_tlg0031.tlg001.obi-lat:1.5   \n",
       "\n",
       "                                                text grela_source  \\\n",
       "0  liber generationis Iesu Christi filii David fi...      vulgate   \n",
       "1  Abraham genuit Isaac Isaac autem genuit Iacob ...      vulgate   \n",
       "2  Iudas autem genuit Phares et Zara de Thamar Ph...      vulgate   \n",
       "3  Aram autem genuit Aminadab Aminadab autem genu...      vulgate   \n",
       "4  Salmon autem genuit Booz de Rachab Booz autem ...      vulgate   \n",
       "\n",
       "                       grela_id_1 author              title  not_before  \\\n",
       "0  vulgate_tlg0031.tlg001.obi-lat   None  Vulgate - Matthew         NaN   \n",
       "1  vulgate_tlg0031.tlg001.obi-lat   None  Vulgate - Matthew         NaN   \n",
       "2  vulgate_tlg0031.tlg001.obi-lat   None  Vulgate - Matthew         NaN   \n",
       "3  vulgate_tlg0031.tlg001.obi-lat   None  Vulgate - Matthew         NaN   \n",
       "4  vulgate_tlg0031.tlg001.obi-lat   None  Vulgate - Matthew         NaN   \n",
       "\n",
       "   not_after lagt_tlg_epithet lagt_genre lagt_provenience noscemus_place  \\\n",
       "0        NaN             None       None             None           None   \n",
       "1        NaN             None       None             None           None   \n",
       "2        NaN             None       None             None           None   \n",
       "3        NaN             None       None             None           None   \n",
       "4        NaN             None       None             None           None   \n",
       "\n",
       "  noscemus_genre noscemus_discipline title_short  emlap_noscemus_id  \\\n",
       "0           None                None        None                NaN   \n",
       "1           None                None        None                NaN   \n",
       "2           None                None        None                NaN   \n",
       "3           None                None        None                NaN   \n",
       "4           None                None        None                NaN   \n",
       "\n",
       "  place_publication place_geonames  author_viaf  title_viaf  date_random  \\\n",
       "0              None           None          NaN         NaN          NaN   \n",
       "1              None           None          NaN         NaN          NaN   \n",
       "2              None           None          NaN         NaN          NaN   \n",
       "3              None           None          NaN         NaN          NaN   \n",
       "4              None           None          NaN         NaN          NaN   \n",
       "\n",
       "   token_count  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grela_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>grela_source</th>\n",
       "      <th>grela_id_1</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>not_before</th>\n",
       "      <th>not_after</th>\n",
       "      <th>lagt_tlg_epithet</th>\n",
       "      <th>lagt_genre</th>\n",
       "      <th>lagt_provenience</th>\n",
       "      <th>noscemus_place</th>\n",
       "      <th>noscemus_genre</th>\n",
       "      <th>noscemus_discipline</th>\n",
       "      <th>title_short</th>\n",
       "      <th>emlap_noscemus_id</th>\n",
       "      <th>place_publication</th>\n",
       "      <th>place_geonames</th>\n",
       "      <th>author_viaf</th>\n",
       "      <th>title_viaf</th>\n",
       "      <th>date_random</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat:1.1</td>\n",
       "      <td>liber generationis Iesu Christi filii David fi...</td>\n",
       "      <td>vulgate</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>None</td>\n",
       "      <td>Vulgate - Matthew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat:1.2</td>\n",
       "      <td>Abraham genuit Isaac Isaac autem genuit Iacob ...</td>\n",
       "      <td>vulgate</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>None</td>\n",
       "      <td>Vulgate - Matthew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat:1.3</td>\n",
       "      <td>Iudas autem genuit Phares et Zara de Thamar Ph...</td>\n",
       "      <td>vulgate</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>None</td>\n",
       "      <td>Vulgate - Matthew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat:1.4</td>\n",
       "      <td>Aram autem genuit Aminadab Aminadab autem genu...</td>\n",
       "      <td>vulgate</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>None</td>\n",
       "      <td>Vulgate - Matthew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat:1.5</td>\n",
       "      <td>Salmon autem genuit Booz de Rachab Booz autem ...</td>\n",
       "      <td>vulgate</td>\n",
       "      <td>vulgate_tlg0031.tlg001.obi-lat</td>\n",
       "      <td>None</td>\n",
       "      <td>Vulgate - Matthew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T12:13:05.166562Z",
     "start_time": "2025-07-21T12:13:03.109859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "WITH subcorpora AS (\n",
    "    SELECT\n",
    "        SUBSTR(grela_id, 0, INSTR(grela_id, '_')) AS subcorpus,\n",
    "        COUNT(DISTINCT grela_id) AS works_N,\n",
    "        COUNT(DISTINCT sentence_id) AS sentences_N,\n",
    "        COUNT(*) AS tokens_N\n",
    "    FROM tokens\n",
    "    GROUP BY subcorpus\n",
    ")\n",
    "SELECT * FROM subcorpora\n",
    "ORDER BY subcorpus;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch as a pandas DataFrame\n",
    "subcorpus_stats_df = conn.execute(query).fetchdf()"
   ],
   "id": "6affbbc9adeed502",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "103594ce26ef4df7905382ae807cb30a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T12:25:41.592932Z",
     "start_time": "2025-07-21T12:25:40.900137Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 27,
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM tokens\n",
    "WHERE grela_id LIKE 'vulgate_tlg0031%' OR grela_id LIKE 'vulgate_tlg0527%';\n",
    "\"\"\"\n",
    "\n",
    "result_df = conn.execute(query).fetchdf()"
   ],
   "id": "d00d2f1fa57df949"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a7fcb84c492e8ba5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T12:13:09.540122Z",
     "start_time": "2025-07-21T12:13:09.534012Z"
    }
   },
   "cell_type": "code",
   "source": "subcorpus_stats_df",
   "id": "b75f6c0c7971b52e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  subcorpus  works_N  sentences_N   tokens_N\n",
       "0        cc     7819     11835457  201939293\n",
       "1     emlap       73       220846    3495212\n",
       "2      lagt     1957      2703678   35808742\n",
       "3  noscemus      996     11802783  139401899\n",
       "4   vulgate       73        35254     603091"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcorpus</th>\n",
       "      <th>works_N</th>\n",
       "      <th>sentences_N</th>\n",
       "      <th>tokens_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc</td>\n",
       "      <td>7819</td>\n",
       "      <td>11835457</td>\n",
       "      <td>201939293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emlap</td>\n",
       "      <td>73</td>\n",
       "      <td>220846</td>\n",
       "      <td>3495212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lagt</td>\n",
       "      <td>1957</td>\n",
       "      <td>2703678</td>\n",
       "      <td>35808742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noscemus</td>\n",
       "      <td>996</td>\n",
       "      <td>11802783</td>\n",
       "      <td>139401899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vulgate</td>\n",
       "      <td>73</td>\n",
       "      <td>35254</td>\n",
       "      <td>603091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T12:13:12.414583Z",
     "start_time": "2025-07-21T12:13:12.406765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "markdown_table = subcorpus_stats_df.set_index(\"subcorpus\").applymap(\"{:,.0f}\".format).to_markdown()\n",
    "print(markdown_table)"
   ],
   "id": "813cb7dcb3f87788",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| subcorpus   | works_N   | sentences_N   | tokens_N    |\n",
      "|:------------|:----------|:--------------|:------------|\n",
      "| cc          | 7,819     | 11,835,457    | 201,939,293 |\n",
      "| emlap       | 73        | 220,846       | 3,495,212   |\n",
      "| lagt        | 1,957     | 2,703,678     | 35,808,742  |\n",
      "| noscemus    | 996       | 11,802,783    | 139,401,899 |\n",
      "| vulgate     | 73        | 35,254        | 603,091     |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54758/3358712856.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  markdown_table = subcorpus_stats_df.set_index(\"subcorpus\").applymap(\"{:,.0f}\".format).to_markdown()\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:09:01.816646Z",
     "start_time": "2025-07-31T09:09:01.810600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_grouped_token_data_with_metadata(conn, lemma: str, pos_tags: list):\n",
    "    \"\"\"\n",
    "    Return one row per matching token (lemma + POS filter) with:\n",
    "      • full sentence token list\n",
    "      • ±10-token concordance window\n",
    "      • minimal work-level metadata\n",
    "    \"\"\"\n",
    "\n",
    "    pos_placeholder = \", \".join(f\"'{tag}'\" for tag in pos_tags)\n",
    "\n",
    "    query = f\"\"\"\n",
    "    /*──────────────── 1. anchor tokens ────────────────*/\n",
    "    WITH target_matches AS (\n",
    "        SELECT\n",
    "            t.sentence_id,\n",
    "            t.grela_id,\n",
    "            s.position                     AS sentence_position,\n",
    "            t.token_id                     AS target_token_id,\n",
    "            t.char_start                   AS target_char_start,\n",
    "            t.char_end                     AS target_char_end\n",
    "        FROM tokens   AS t\n",
    "        JOIN sentences AS s USING (sentence_id)\n",
    "        WHERE  t.lemma = ?\n",
    "          AND  t.pos   IN ({pos_placeholder})\n",
    "    ),\n",
    "\n",
    "    /*──────────────── 2. ±1-sentence context ──────────*/\n",
    "    context_3sents AS (\n",
    "        SELECT\n",
    "            tm.sentence_id,\n",
    "            STRING_AGG(s.text, ' | ' ORDER BY s.position) AS context_3sents\n",
    "        FROM target_matches tm\n",
    "        JOIN sentences s\n",
    "          ON s.grela_id = tm.grela_id\n",
    "         AND s.position BETWEEN tm.sentence_position - 1\n",
    "                            AND tm.sentence_position + 1\n",
    "        GROUP BY tm.sentence_id\n",
    "    ),\n",
    "\n",
    "    /*──────────────── 3. full token list per sentence ─*/\n",
    "    sentence_tokens AS (\n",
    "        SELECT\n",
    "            sentence_id,\n",
    "            LIST(\n",
    "              STRUCT_PACK(\n",
    "                 token_id    := token_id,\n",
    "                 token_text  := token_text,\n",
    "                 lemma       := lemma,\n",
    "                 pos         := pos,\n",
    "                 char_start  := char_start,\n",
    "                 char_end    := char_end,\n",
    "                 sentence_id := sentence_id\n",
    "              )\n",
    "              ORDER BY token_id\n",
    "            ) AS tokens\n",
    "        FROM tokens\n",
    "        WHERE sentence_id IN (SELECT DISTINCT sentence_id FROM target_matches)\n",
    "        GROUP BY sentence_id\n",
    "    ),\n",
    "\n",
    "    /*──────────────── 4. ±10-token concordance window ─*/\n",
    "    concordance_tokens AS (\n",
    "        SELECT\n",
    "            tm.sentence_id,\n",
    "            tm.target_token_id,\n",
    "            LIST(\n",
    "              STRUCT_PACK(\n",
    "                 token_id    := ct.token_id,\n",
    "                 token_text  := ct.token_text,\n",
    "                 lemma       := ct.lemma,\n",
    "                 pos         := ct.pos,\n",
    "                 char_start  := ct.char_start,\n",
    "                 char_end    := ct.char_end,\n",
    "                 sentence_id := ct.sentence_id\n",
    "              )\n",
    "              ORDER BY ct.token_id\n",
    "            ) AS concordance_tokens\n",
    "        FROM target_matches tm\n",
    "        JOIN tokens        ct\n",
    "          ON ct.grela_id = tm.grela_id\n",
    "         AND ct.token_id BETWEEN tm.target_token_id - 10\n",
    "                            AND tm.target_token_id + 10\n",
    "        GROUP BY tm.sentence_id, tm.target_token_id\n",
    "    )\n",
    "\n",
    "    /*──────────────── 5. final projection (custom column order) ─────*/\n",
    "    SELECT\n",
    "        w.author,\n",
    "        w.title,\n",
    "        tm.grela_id AS grela_id,\n",
    "        tm.sentence_id,\n",
    "        s.text                    AS sentence_text,\n",
    "        c3.context_3sents,\n",
    "\n",
    "        st.tokens                AS tokens,\n",
    "        ct.concordance_tokens    AS concordance_tokens,\n",
    "\n",
    "        w.not_before,\n",
    "        w.not_after,\n",
    "        w.date_random,\n",
    "        w.lagt_genre,\n",
    "        w.lagt_provenience,\n",
    "        w.noscemus_genre,\n",
    "        w.noscemus_discipline,\n",
    "\n",
    "        tm.target_token_id,\n",
    "        tm.target_char_start,\n",
    "        tm.target_char_end\n",
    "\n",
    "    FROM target_matches      tm\n",
    "    JOIN sentences           s   USING (sentence_id)\n",
    "    JOIN works               w   ON w.grela_id = tm.grela_id\n",
    "    LEFT JOIN context_3sents c3  USING (sentence_id)\n",
    "    LEFT JOIN sentence_tokens st USING (sentence_id)\n",
    "    LEFT JOIN concordance_tokens ct\n",
    "           ON  ct.sentence_id    = tm.sentence_id\n",
    "          AND ct.target_token_id = tm.target_token_id\n",
    "    ORDER BY tm.sentence_id, tm.target_token_id;\n",
    "    \"\"\"\n",
    "\n",
    "    return conn.execute(query, [lemma]).fetchdf()"
   ],
   "id": "d45afe121c99db26",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:09:44.453257Z",
     "start_time": "2025-07-31T09:09:07.866143Z"
    }
   },
   "cell_type": "code",
   "source": "result_df = get_grouped_token_data_with_metadata(conn, lemma=\"deus\", pos_tags=[\"NOUN\", \"PROPN\", \"ADJ\"])",
   "id": "dce91d6e96da0647",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f8be1476e3d42f88404fc668fb32c42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:09:50.799616Z",
     "start_time": "2025-07-31T09:09:50.795153Z"
    }
   },
   "cell_type": "code",
   "source": "len(result_df)",
   "id": "4125d420c1a2c85b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189254"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:12:09.094355Z",
     "start_time": "2025-07-31T09:12:09.088345Z"
    }
   },
   "cell_type": "code",
   "source": "result_df.iloc[0][\"concordance_tokens\"]",
   "id": "ece016410a4a05b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'token_id': 183835477, 'token_text': 'scholari', 'lemma': 'scholaris', 'pos': 'VERB', 'char_start': 25, 'char_end': 33, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835478, 'token_text': 'ferula', 'lemma': 'ferula', 'pos': 'NOUN', 'char_start': 34, 'char_end': 40, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835479, 'token_text': 'erudiendi', 'lemma': 'erudio', 'pos': 'VERB', 'char_start': 41, 'char_end': 50, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835480, 'token_text': 'essent', 'lemma': 'sum', 'pos': 'AUX', 'char_start': 51, 'char_end': 57, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835481, 'token_text': ',', 'lemma': ',', 'pos': 'PUNCT', 'char_start': 57, 'char_end': 58, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835482, 'token_text': 'quia', 'lemma': 'quia', 'pos': 'SCONJ', 'char_start': 59, 'char_end': 63, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835483, 'token_text': 'ignauiae', 'lemma': 'ignauius', 'pos': 'NOUN', 'char_start': 64, 'char_end': 72, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835484, 'token_text': ',', 'lemma': ',', 'pos': 'PUNCT', 'char_start': 72, 'char_end': 73, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835485, 'token_text': 'socordiae', 'lemma': 'socordia', 'pos': 'NOUN', 'char_start': 74, 'char_end': 83, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835486, 'token_text': 'et', 'lemma': 'et', 'pos': 'CCONJ', 'char_start': 84, 'char_end': 86, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835487, 'token_text': 'deo', 'lemma': 'deus', 'pos': 'NOUN', 'char_start': 87, 'char_end': 90, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835488, 'token_text': 'suo', 'lemma': 'suus', 'pos': 'DET', 'char_start': 91, 'char_end': 94, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835489, 'token_text': 'uentri', 'lemma': 'uenter', 'pos': 'NOUN', 'char_start': 95, 'char_end': 101, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835490, 'token_text': 'manus', 'lemma': 'manus', 'pos': 'NOUN', 'char_start': 102, 'char_end': 107, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835491, 'token_text': 'dederunt', 'lemma': 'do', 'pos': 'VERB', 'char_start': 108, 'char_end': 116, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835492, 'token_text': ',', 'lemma': ',', 'pos': 'PUNCT', 'char_start': 116, 'char_end': 117, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835493, 'token_text': 'dum', 'lemma': 'dum', 'pos': 'SCONJ', 'char_start': 118, 'char_end': 121, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835494, 'token_text': 'instrui', 'lemma': 'instruo', 'pos': 'VERB', 'char_start': 122, 'char_end': 129, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835495, 'token_text': 'refugiunt', 'lemma': 'refugio', 'pos': 'VERB', 'char_start': 130, 'char_end': 139, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835496, 'token_text': 'ad', 'lemma': 'ad', 'pos': 'ADP', 'char_start': 140, 'char_end': 142, 'sentence_id': 'cc_10003_335'},\n",
       "       {'token_id': 183835497, 'token_text': 'grauitatem', 'lemma': 'grauitas', 'pos': 'NOUN', 'char_start': 143, 'char_end': 153, 'sentence_id': 'cc_10003_335'}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "981daba2c530e1f0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
